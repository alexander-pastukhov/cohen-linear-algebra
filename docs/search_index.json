[["index.html", "R-version of the code for Linear Algebra: Theory, Intuition, Code by Mike X Cohen Introduction Libraries the code relies upon", " R-version of the code for Linear Algebra: Theory, Intuition, Code by Mike X Cohen Alexander (Sasha) Pastukhov 2021-03-26 Introduction This is an R-version of the code for Linear Algebra: Theory, Intuition, Code by Mike X Cohen. I have tried to keep the code as close as possible to the original even if it went against the spirit of R. E.g., loops can be replaced with vectorized operations, tidyverse piping approach, or apply()/replicate()/purrr::map(). In most cases, I use library:: disambiguation to make it easier to understand which function belongs to which package, instead of importing libraries via library(). Libraries the code relies upon Matrix calculations pracma geigen for generalized eigenvalues matrixcalc for raising matrix to the power Tidyverse packages for data wrangling, you can install all relevant packages (including ggplot2) via install.packages(\"tidyverse\"). dplyr tidyr reshape2 Graphics ggplot2 for plotting plotly for 3D surface plot patchwork to create a composite figure out of multiple plots RColorBrewer for color schemes imager for working with images "],["code.html", "Code Chapter 2 Chapter 3 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 12 Chapter 13 Chapter 15 Chapter 16 Chapter 17", " Code Chapter 2 Code block 2.1/2.2 aScalar &lt;- 4 Code block 2.3/2.4 This is a ggplot2 rather than base R version. But ggplot2 figures do look so much better. library(ggplot2) ## Warning: package &#39;ggplot2&#39; was built under R version 4.0.4 v &lt;- c(2, -1) ggplot(data=NULL, aes(x = c(0, v[1]), y=c(0, v[2]))) + geom_line() + geom_point(aes(x=v[1], y=v[2])) + scale_x_continuous(name=expression(paste(X[1], &quot; dim.&quot;)), limits = c(-3, 3)) + scale_y_continuous(name=expression(paste(X[2], &quot; dim.&quot;)), limits = c(-3, 3)) + coord_equal() Code block 2.5/2.6 In R atomic vectors are created via c() function but, technically, they are neither column, nor row vectors. Matrix multiplication manual states that it multiplies two matrices, if they are conformable. If one argument is a vector, it will be promoted to either a row or column matrix to make the two arguments conformable. If both are vectors of the same length, it will return the inner product (as a matrix). At the same time, transposing an atomic vector t(c(...)) transforms it into a single row matrix, thus a row vector, hinting that deep down an outcome of c() is a column vector. To avoid ambiguity, I will use single row and single column matrices for, respectively, row and column vectors. v1 &lt;- matrix(c(2, 5, 5, 7), nrow = 1) # row vector v2 &lt;- matrix(c(2, 5, 5, 7), ncol = 1) # column vector v3 &lt;- matrix(c(2, 5, 5, 7)) # also a column vector Code block 2.7/2.8 v1 &lt;- matrix(c(2, 5, 5, 7), nrow = 1) # row vector v1a &lt;- t(c(2, 5, 5, 7)) # also a row vector v2 &lt;- t(v1) # column vector Code block 2.9/2.10 For this example, you can also use atomic vectors directly without turning them into a column vector / single column matrix. v1 &lt;- matrix(c(2, 5, 4, 7), ncol=1) v2 &lt;- matrix(c(4, 1, 0, 2), ncol=1) v3 &lt;- 4 * v1 - 2 * v2 Chapter 3 Code block 3.1/3.2 There is no explicit dot product function in base R but there are multiple implementations in various libraries such as pracma used here. v1 &lt;- matrix(c(2, 5, 4, 7), ncol=1) v2 &lt;- matrix(c(4, 1, 0, 2), ncol=1) dp &lt;- pracma::dot(v1, v2) However, a matrix multiplication of atomic vectors (we can convert a matrix back to an atomic vector via c() or as.vector()) gives us the dot product (well, the inner product, which is why the result is a 1-by-1 matrix). dp &lt;- c(v1) %*% as.vector(v2) Code block 3.3/3.4 l1 &lt;- 1 l2 &lt;- 2 l3 &lt;- -3 v1 &lt;- matrix(c(4, 5, 1), ncol=1) v2 &lt;- matrix(c(-4, 0, -4), ncol=1) v3 &lt;- matrix(c(1, 3, 2), ncol=1) l1 * v1 + l2 * v2 + l3 * v3 ## [,1] ## [1,] -7 ## [2,] -4 ## [3,] -13 Code block 3.5/3.6 To compute the outer product, we must use atomic vectors, thus Ive skipped the whole creating-column-vector-as-a-matrix thing. v1 &lt;- c(2, 5, 4, 7) v2 &lt;- c(4, 1, 0, 2) op &lt;- outer(v1, v2) op &lt;- v1 %o% v2 # alternative call as operation Alternatively, if we do start with vectors as single column matrices v1 &lt;- matrix(c(2, 5, 4, 7), ncol=1) v2 &lt;- matrix(c(4, 1, 0, 2), ncol=1) op &lt;- outer(c(v1), c(v2)) op &lt;- c(v1) %o% c(v2) # alternative call as operation Code block 3.7/3.8 v1 &lt;- matrix(c(2, 5, 4, 7), ncol=1) v2 &lt;- matrix(c(4, 1, 0, 2), ncol=1) v3 &lt;- v1 * v2 Code block 3.9/3.10 Please note that you need to explicitly specify the 2-norm via type=\"2\", as the one norm is used by default. v &lt;- matrix(c(2, 5, 4, 7), ncol=1) vMag &lt;- norm(v, type=&quot;2&quot;) v_unit &lt;- v / vMag Chapter 5 Code block 5.1/5.2 There is only one way to transpose a matrix in R: via function t(). A &lt;- matrix(runif(n=2*5), nrow=2, ncol=5) At1 &lt;- t(A) Code block 5.3/5.4 I &lt;- diag(4) O &lt;- matrix(1, nrow=4, ncol=1) # or rep(1, times=4) to create an atomic vector Z &lt;- matrix(0, nrow=4, ncol=4) Code block 5.5/5.6 D &lt;- diag(c(1, 2, 3, 5)) # diagonal matrix R &lt;- matrix(runif(n = 3 * 4), nrow=3, ncol=4) d &lt;- diag(R) # diagonal elements Code block 5.7/5.8 In r cbind() and rbind() concatenate, respectively, by column and row. A &lt;- matrix(runif(n = 3 * 5), nrow=3, ncol=5) B &lt;- matrix(runif(n = 3 * 4), nrow=3, ncol=4) AB &lt;- cbind(A, B) Code block 5.9/5.10 There are two ways to compute lower and upper triangular parts of a matrix. First, to use tril() and triu() function from pracma library. A &lt;- matrix(runif(n = 5 * 5), nrow=5, ncol=5) L &lt;- pracma::tril(A) U &lt;- pracma::triu(A) Alternatively, you can use base R functions lower.tri() and upper.tri() that give you a matrix of the same size with logical values indicating whether an element belongs to, respectively, lower or upper triangle. Note that by default, the diagonal is not included! A &lt;- matrix(runif(n = 5 * 5), nrow=5, ncol=5) L &lt;- A # by setting the UPPER triangular part to 0, we get the LOWER triangular part and the diagonal L[upper.tri(L)] &lt;- 0 U &lt;- A # by setting the LOWER triangular part to 0, we get the UPPER triangular part and the diagonal U[lower.tri(U)] &lt;- 0 Code block 5.11/5.12 Note that there is a toeplitz() function in stats (base R) and Topelitz() (note the first capital letter) in pracma library. Here, I use base R version. t &lt;- c(1, 2, 3, 4) T &lt;- stats::toeplitz(t) H &lt;- pracma::hankel(t, b= c(t[-1], t[1])) ## Warning in pracma::hankel(t, b = c(t[-1], t[1])): a[n] not equal to b[1], b[1] ## set to a[n]. Code block 5.13/5.14 l &lt;- 0.01 I &lt;- diag(4) A &lt;- matrix(runif(4 * 4), nrow=4, ncol=4) As &lt;- A + l * I Code block 5.15/5.16 Base R does not implement trace function, as it is simply a sum(diag(M)). However, you can use Trace() from pracma library. A &lt;- matrix(runif(4 * 4), nrow=4, ncol=4) tr &lt;- pracma::Trace(A) Chapter 6 Code block 6.1/6.2 M1 &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) M2 &lt;- matrix(runif(n=3*5), nrow=3, ncol=5) C &lt;- M1 %*% M2 Code block 6.3/6.4 A &lt;- matrix(runif(n=2*2), nrow=2, ncol=2) B &lt;- matrix(runif(n=2*2), nrow=2, ncol=2) C1 &lt;- A %*% B C2 &lt;- B %*% A Code block 6.5/6.6 M1 &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) M2 &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) C &lt;- M1 * M2 Code block 6.7/6.8 Note that by default, matrix is constructed by column. To match the code, we need to use byrow=TRUE option. A &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow=2, byrow = TRUE) c(A) ## [1] 1 4 2 5 3 6 Code block 6.9/6.10 A &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) B &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) f &lt;- pracma::Trace(t(A) %*% B) Code block 6.11/6.12 A &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) norm(A, type=&quot;F&quot;) ## [1] 2.226515 Chapter 7 Code block 7.1/7.2 You can use Rank() from the pracma library. Alternatively, you can use rankMatrix() function from the Matrix library, which in addition to the rank itself, returns information on the method used to estimate the rank via attributes. A &lt;- matrix(runif(n=3*6), nrow=3, ncol=6) r1 &lt;- pracma::Rank(A) r2 &lt;- Matrix::rankMatrix(A) Code block 7.3/7.4 s &lt;- runif(n=1) A &lt;- matrix(runif(n=3*5), nrow=3, ncol=5) r1 &lt;- pracma::Rank(A) r2 &lt;- pracma::Rank(s * A) print(c(r1, r2)) ## [1] 3 3 Code block 7.5/7.6 Source code for Rank() function from pracma library. pracma::Rank ## function (M) ## { ## if (length(M) == 0) ## return(0) ## if (!is.numeric(M)) ## stop(&quot;Argument &#39;M&#39; must be a numeric matrix.&quot;) ## if (is.vector(M)) ## M &lt;- matrix(c(M), nrow = length(M), ncol = 1) ## r1 &lt;- qr(M)$rank ## sigma &lt;- svd(M)$d ## tol &lt;- max(dim(M)) * max(sigma) * .Machine$double.eps ## r2 &lt;- sum(sigma &gt; tol) ## if (r1 != r2) ## warning(&quot;Rank calculation may be problematic.&quot;) ## return(r2) ## } ## &lt;bytecode: 0x0000000015c31328&gt; ## &lt;environment: namespace:pracma&gt; Source code for rankMatrix() function from Matrix library. Matrix::rankMatrix ## function (x, tol = NULL, method = c(&quot;tolNorm2&quot;, &quot;qr.R&quot;, &quot;qrLINPACK&quot;, ## &quot;qr&quot;, &quot;useGrad&quot;, &quot;maybeGrad&quot;), sval = svd(x, 0, 0)$d, warn.t = TRUE) ## { ## stopifnot(length(d &lt;- dim(x)) == 2) ## p &lt;- min(d) ## method &lt;- match.arg(method) ## if (useGrad &lt;- (method %in% c(&quot;useGrad&quot;, &quot;maybeGrad&quot;))) { ## stopifnot(length(sval) == p, diff(sval) &lt;= 0) ## if (sval[1] == 0) { ## useGrad &lt;- FALSE ## method &lt;- eval(formals()[[&quot;method&quot;]])[[1]] ## } ## else { ## ln.av &lt;- log(abs(sval)) ## diff1 &lt;- diff(ln.av) ## if (method == &quot;maybeGrad&quot;) { ## grad &lt;- (min(ln.av) - max(ln.av))/p ## useGrad &lt;- !is.na(grad) &amp;&amp; min(diff1) &lt;= min(-3, ## 10 * grad) ## } ## } ## } ## if (!useGrad) { ## x.dense &lt;- is.numeric(x) || is(x, &quot;denseMatrix&quot;) ## if ((Meth &lt;- method) == &quot;qr&quot;) ## method &lt;- if (x.dense) ## &quot;qrLINPACK&quot; ## else &quot;qr.R&quot; ## else Meth &lt;- substr(method, 1, 2) ## if (Meth == &quot;qr&quot;) { ## if (is.null(tol)) ## tol &lt;- max(d) * .Machine$double.eps ## } ## else { ## if (is.null(tol)) { ## if (!x.dense &amp;&amp; missing(sval) &amp;&amp; prod(d) &gt;= 100000L) ## warning(gettextf(&quot;rankMatrix(&lt;large sparse Matrix&gt;, method = &#39;%s&#39;) coerces to dense matrix.\\n Probably should rather use method = &#39;qr&#39; !?&quot;, ## method), immediate. = TRUE, domain = NA) ## stopifnot(diff(sval) &lt;= 0) ## tol &lt;- max(d) * .Machine$double.eps ## } ## else stopifnot((tol &lt;- as.numeric(tol)[[1]]) &gt;= 0) ## } ## } ## structure(if (useGrad) ## which.min(diff1) ## else if (Meth == &quot;qr&quot;) { ## if ((do.t &lt;- (d[1L] &lt; d[2L])) &amp;&amp; warn.t) ## warning(gettextf(&quot;rankMatrix(x, method=&#39;qr&#39;): computing t(x) as nrow(x) &lt; ncol(x)&quot;)) ## q.r &lt;- qr(if (do.t) ## t(x) ## else x, tol = tol, LAPACK = method != &quot;qrLINPACK&quot;) ## if (x.dense &amp;&amp; (method == &quot;qrLINPACK&quot;)) ## q.r$rank ## else { ## diagR &lt;- if (x.dense) ## diag(q.r$qr) ## else diag(q.r@R) ## d.i &lt;- abs(diagR) ## if ((mdi &lt;- max(d.i)) &gt; 0) ## sum(d.i &gt;= tol * mdi) ## else 0L ## } ## } ## else if (sval[1] &gt; 0) ## sum(sval &gt;= tol * sval[1]) ## else 0L, method = method, useGrad = useGrad, tol = if (useGrad) ## NA ## else tol) ## } ## &lt;bytecode: 0x00000000200e59f8&gt; ## &lt;environment: namespace:Matrix&gt; Chapter 8 Code block 8.1/8.2 A &lt;- matrix(runif(n=3*4), nrow=3, ncol=4) pracma::nullspace(A) ## [,1] ## [1,] -0.52625099 ## [2,] 0.03707307 ## [3,] -0.60824506 ## [4,] 0.59306275 Chapter 9 Code block 9.1/9.2 z &lt;- complex(real=3, imaginary=4) Z &lt;- complex(length.out=2, real=0, imaginary=0) Z[1] &lt;- 3 + 4i Code block 9.3/9.4 Base R does not have a function that generates random integers on the interval. I will use sample() with replacement from the range of integers to replicate this. Also note that I have renamed i to im to minimize the confusion. r &lt;- sample(-3:4, size=3, replace = TRUE) im &lt;- sample(-3:4, size=3, replace = TRUE) Z &lt;- r + im * 1i print(Z) ## [1] 3+0i 1+0i 1+2i print(Conj(Z)) ## [1] 3+0i 1+0i 1-2i Code block 9.5/9.6 pracma::dot() implements the Hermitian dot product. v &lt;- c(0, 1i) pracma::dot(v, v) ## [1] 1+0i Chapter 10 Code block 10.1/10.2 You can use pracma::lu() function but note that it works only on square, positive definite matrices. # Using the square matrix from practice problem b A &lt;- matrix(c(2, 0, 1, 1, 1, 2, 3, 1, 3), nrow=3, byrow=TRUE) pracma::lu(A) ## $L ## [,1] [,2] [,3] ## [1,] 1.0 0 0 ## [2,] 0.5 1 0 ## [3,] 1.5 1 1 ## ## $U ## [,1] [,2] [,3] ## [1,] 2 0 1.0 ## [2,] 0 1 1.5 ## [3,] 0 0 0.0 Code block 10.3/10.4 A &lt;- matrix(runif(n=2*4), nrow=2, ncol=4) pracma::rref(A) ## [,1] [,2] [,3] [,4] ## [1,] 1 0 0.5710462 0.7131498 ## [2,] 0 1 -0.1451739 0.3724851 Chapter 11 Code block 11.1/11.2 A &lt;- matrix(runif(n=3*3), nrow=3, ncol=3) det(A) ## [1] 0.06305531 Chapter 12 Code block 12.1/12.2 In R, you find the inverse via solve(). The latter solves an equation \\(Ax = b\\), omitting the second argument defaults b = I and the equation is solved to find the inverse. I have added round() to make it easier to see that \\(A A^-1\\) produces an identity matrix. A &lt;- matrix(rnorm(n=3*3), nrow=3, ncol=3) Ai &lt;- solve(A) round(A %*% Ai, 4) ## [,1] [,2] [,3] ## [1,] 1 0 0 ## [2,] 0 1 0 ## [3,] 0 0 1 Code block 12.3/12.4 A &lt;- matrix(rnorm(n=3*3), nrow=3, ncol=3) Acat &lt;- cbind(A, diag(1, nrow=3, ncol=3)) Ar &lt;- pracma::rref(Acat) # RREF Ar &lt;- Ar[, 4:6] # keep inverse Ai &lt;- solve(A) round(Ar - Ai, 4) ## [,1] [,2] [,3] ## [1,] 0 0 0 ## [2,] 0 0 0 ## [3,] 0 0 0 Code block 12.5/12.6 A &lt;- matrix(rnorm(n=5*3), nrow=5, ncol=3) Al &lt;- solve(t(A) %*% A) %*% t(A) round(Al %*% A, 4) ## [,1] [,2] [,3] ## [1,] 1 0 0 ## [2,] 0 1 0 ## [3,] 0 0 1 Code block 12.7/12.8 A &lt;- matrix(rnorm(n=3*3), nrow=3, ncol=3) A[2, ] &lt;- A[1, ] Api &lt;- pracma::pinv(A) Api %*% A ## [,1] [,2] [,3] ## [1,] 0.68405603 0.01263654 0.46471894 ## [2,] 0.01263654 0.99949459 -0.01858697 ## [3,] 0.46471894 -0.01858697 0.31644938 Chapter 13 Code block 13.1/13.2 A &lt;- matrix(c(1, 2, 3, 1, 1, 1), nrow=3, byrow=TRUE) b &lt;- matrix(c(5.5, -3.5, 1.5), nrow=3) lsfit(A, b)$coefficients ## Intercept X1 X2 ## 0.0 -2.5 4.0 Code block 13.3/13.4 In R, you first perform QT decomposition via qr() and get an object. Then, you can extract component matrices of the decomposition via qr.Q() and qr.R(). A &lt;- matrix(rnorm(n=4*3), nrow=4, ncol=3) QR &lt;- qr(A) Q &lt;- qr.Q(QR) R &lt;- qr.R(QR) Chapter 15 Code block 15.1/15.2 A &lt;- matrix(c(2, 3, 3, 2), nrow=2, ncol=2, byrow=TRUE) eigenA &lt;- eigen(A) V &lt;- eigenA$vectors L &lt;- eigenA$values Code block 15.3/15.4 n &lt;- 3 A &lt;- matrix(rnorm(n=n^2), nrow=n, ncol=n) B &lt;- matrix(rnorm(n=n^2), nrow=n, ncol=n) eigenAB &lt;- geigen::geigen(A, B) evecs &lt;- eigenAB$vectors evals &lt;- eigenAB$vals Chapter 16 Code block 16.1/16.2 Note that by default number of left (matrix U) and right (matrix V) singular vectors is determined as, respectively, nu = min(n, p) and nv = min(n, p) for the n Ã— p matrix. Therefore, I included nv=ncol(A) to replicate output by Python. Also note that R, like Matlab, return V. Also note that singular values attribute is d and it is a vector not a diagonal matrix. A &lt;- matrix(c(1, 1, 0, 0, 1, 1), nrow=2, ncol=3, byrow=TRUE) svdA &lt;- svd(A, nv=ncol(A)) U &lt;- svdA$u s &lt;- svdA$d V &lt;- svdA$v Code block 16.3/16.4 A &lt;- matrix(rnorm(n=5^2), nrow=5, ncol=5) s &lt;- svd(A)$d condnum &lt;- max(s) / min(s) #compare above with pracma::cond() print(c(condnum, pracma::cond(A))) ## [1] 14.13711 14.13711 Chapter 17 Code block 17.1/17.2 m &lt;- 4 A &lt;- matrix(rnorm(n=m^2), nrow=m, ncol=m) v &lt;- matrix(rnorm(n=m), nrow=1, ncol=m) v %*% A %*% t(v) ## [,1] ## [1,] -1.686999 "],["solutions-for-code-challenges.html", "Solutions for code challenges Chapter 2 Chapter 3 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Chapter 9 Chapter 10 Chapter 11 Chapter 12 Chapter 13 Chapter 14 Chapter 15 Chapter 16 Chapter 18 Chapter 19", " Solutions for code challenges Chapter 2 library(ggplot2) v &lt;- c(1, 2) s &lt;- rnorm(10) all_vectors &lt;- data.frame(xend = c(v[1], v[1] * s), yend = c(v[2], v[2] * s), Vector = c(&quot;Original&quot;, rep(&quot;Scaled&quot;, length(s))), x = 0, y = 0) ggplot(data=all_vectors, aes(x=x, y=y, xend=xend, yend=yend, color=Vector)) + geom_segment(arrow= arrow(length = unit(0.03, &quot;npc&quot;))) + xlim(-4, 4) + ylim(-4, 4) + coord_equal() Chapter 3 Exercise 1 v1 &lt;- c(1, 2, 3, 4, 5) v2 &lt;- c(2, 3, 4, 5, 6) v3 &lt;- c(3, 4, 5, 6, 7) w &lt;- c(-1, 3, 2) result &lt;- v1 * w[1] + v2 * w[2] + v3* w[3] Exercise 2 v &lt;- c(7, 4, -5, 8, 3) o &lt;- rep(1, length(v)) ave &lt;- pracma::dot(v, o) / length(v) Exercise 3 v &lt;- c(7, 4, -5, 8, 3) w &lt;- runif(length(v)) wAve &lt;- pracma::dot(v, w / sum(w)) Chapter 5 Exercise 1 A &lt;- matrix(runif(n=4*2), nrow=4, ncol=2) B &lt;- matrix(runif(n=4*2), nrow=4, ncol=2) C &lt;- matrix(NA, nrow=2, ncol=2) for(coli in 1:2){ for(colj in 1:2){ C[coli, colj] &lt;- pracma::dot(A[, coli], B[, colj]) } } Exercise 2 A &lt;- matrix(runif(n=4*4), nrow=4, ncol=4) Al &lt;- pracma::tril(A) S &lt;- Al + t(Al) Exercise 3 D &lt;- matrix(0, nrow=4, ncol=8) for(d in 1:min(dim(D))){ D[d, d] &lt;- d } # or D &lt;- diag(1:4, nrow=4, ncol=8) Chapter 6 Exercise 1 A &lt;- matrix(runif(n=2*4), nrow=2, ncol=4) B &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) C1 &lt;- matrix(0, nrow=2, ncol=3) for(i in 1:4){ C1 &lt;- C1 + outer(A[, i], B[i, ]) } C1 - A %*% B ## [,1] [,2] [,3] ## [1,] 0 0 0 ## [2,] 0 0 0 Exercise 2 D &lt;- diag(1:4) A &lt;- matrix(runif(n=4*4), nrow=4, ncol=4) C1 &lt;- D * A C2 &lt;- D %*% A print(diag(C1)) ## [1] 0.4407820 0.4891542 1.0255423 0.1605507 print(diag(C2)) ## [1] 0.4407820 0.4891542 1.0255423 0.1605507 Exercise 3 A &lt;- diag(runif(3)) C1 &lt;- (t(A) + A) / 2 C2 &lt;- t(A) %*% A C1 - sqrt(C2) ## [,1] [,2] [,3] ## [1,] 0 0 0 ## [2,] 0 0 0 ## [3,] 0 0 0 Exercise 4 Note that norm() requires a matrix as an input, therefore, we convert an atomic vector to a matrix for the norm computation. m &lt;- 5 A &lt;- matrix(runif(n=m*m), nrow=m, ncol=m) v &lt;- runif(n=m) LHS &lt;- norm(A %*% v, type = &quot;F&quot;) RHS &lt;- norm(A, type = &quot;F&quot;) * norm(matrix(v), type=&quot;F&quot;) RHS - LHS # should always be positive ## [1] 0.3911112 Chapter 7 Exercise 1 A &lt;- matrix(runif(n=9*2), nrow=9, ncol=2) B &lt;- matrix(runif(n=2*16), nrow=2, ncol=16) C &lt;- A %*% B Exercise 2 Z &lt;- matrix(0, nrow=5, ncol=5) N &lt;- matrix(runif(5 * 5), nrow=5, ncol=5) ZN &lt;- Z + N * .Machine$double.eps * 1e-307 print(pracma::Rank(Z)) ## [1] 0 print(pracma::Rank(ZN)) ## Warning in pracma::Rank(ZN): Rank calculation may be problematic. ## [1] 4 print(norm(ZN, type = &quot;F&quot;)) ## [1] 5.434722e-323 Chapter 8 Exercise 1 A &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) %*% matrix(runif(n=3*4), nrow=3, ncol=4) B &lt;- matrix(runif(n=4*3), nrow=4, ncol=3) %*% matrix(runif(n=3*4), nrow=3, ncol=4) n &lt;- pracma::nullspace(A) print(B %*% A %*% n) # zeros vector ## [,1] ## [1,] 5.551115e-17 ## [2,] -5.551115e-17 ## [3,] -1.665335e-16 ## [4,] 1.110223e-16 print(A %*% B %*% n) # not zeros vector ## [,1] ## [1,] 0.22722870 ## [2,] 0.21246335 ## [3,] 0.05179135 ## [4,] 0.03917362 Exercise 2 A &lt;- matrix(runif(n=16*9), nrow=16, ncol=9) %*% matrix(runif(n=9*11), nrow=9, ncol=11) rn &lt;- pracma::nullspace(A) ln &lt;- pracma::nullspace(t(A)) r &lt;- pracma::Rank(A) print(ncol(rn) + r) ## [1] 11 print(ncol(ln) + r) ## [1] 16 Chapter 9 Exercise 1 Base R does not implement Hermitian transpose directly and you are advised to compute it via Conj(t(A)), see Notes for [t()](https://stat.ethz.ch/R-manual/R-devel/library/base/html/t.html function. U &lt;- 0.5 * matrix(c(1+1i, 1-1i, 1-1i, 1+1i), nrow=2, ncol=2) print(U %*% Conj(t(U))) # Hermitian ## [,1] [,2] ## [1,] 1+0i 0+0i ## [2,] 0+0i 1+0i print(U %*% t(U)) # not Hermitian ## [,1] [,2] ## [1,] 0+0i 1+0i ## [2,] 1+0i 0+0i Exercise 2 In contrast to Matlab, a complex matrix isSymmetric() only if it is Hermitian. r &lt;- matrix(runif(n=3*3), nrow=3, ncol=3) im &lt;- matrix(runif(n=3*3), nrow=3, ncol=3) A &lt;- r + im * 1i A1 &lt;- A + Conj(t(A)) A2 &lt;- A %*% Conj(t(A)) isSymmetric(A1) ## [1] TRUE isSymmetric(A2) ## [1] TRUE Chapter 10 Exercise 1 A &lt;- matrix(c(2, 0, -3, 3, 1, 4, 1, 0, -1), nrow=3, byrow=TRUE) x &lt;- matrix(c(2, 3, 4), ncol=1) b &lt;- A %*% x Exercise 2 A &lt;- matrix(runif(n=3*6), nrow=3, ncol=6) pracma::rref(A) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 0 0.4892414 1.882597 1.3067571 ## [2,] 0 1 0 -0.5072360 1.562761 0.2554863 ## [3,] 0 0 1 0.8116224 -1.923485 -0.2257580 Chapter 11 Exercise 1 A &lt;- matrix(sample(0:10, size=4*4, replace=TRUE), nrow=4, ncol=4) b &lt;- sample(-10:-1, size=1) print(det(b * A)) ## [1] 159375 print(b^nrow(A) * det(A)) ## [1] 159375 Exercise 2 library(ggplot2) ns &lt;- 3:30 iters &lt;- 100 dets &lt;- matrix(0, nrow=length(ns), ncol = iters) for(ni in 1:length(ns)){ for(it in 1:iters){ A &lt;- matrix(rnorm(n=ns[ni]^2), nrow=ns[ni], ncol=ns[ni]) # step 1 A[, 1] &lt;- A[, 2] # step 2 dets[ni, it] &lt;- abs(det(A)) # step 3 } } dets_summary &lt;- data.frame(MatrixSize = ns, LogDeterminant = log(apply(dets, MARGIN = 1, mean))) ggplot(data=dets_summary, aes(x=MatrixSize, y=LogDeterminant)) + geom_line() + geom_point() + xlab(&quot;Matrix size&quot;) + ylab(&quot;Log determinant&quot;) Chapter 12 Exercise 1 # create matrix m &lt;- 4 A &lt;- matrix(rnorm(m^2), nrow=m, ncol=m) M &lt;- matrix(0, nrow=m, ncol=m) G &lt;- matrix(0, nrow=m, ncol=m) # compute minors matrix for(i in 1:m){ for(j in 1:m){ ## select rows and cols # implementation matching the original rows &lt;- rep(TRUE, m) rows[i] &lt;- FALSE cols &lt;- rep(TRUE, m) cols[j] &lt;- FALSE M[i, j] &lt;- det(A[rows, cols]) # a simpler R-version using negative (excluding) indexing M[i, j] &lt;- det(A[-i, -j]) # compute G G[i, j] &lt;- (-1)^(i + j) } } # compute C C &lt;- M * G # compute A Ainv &lt;- t(C) / det(A) AinvI &lt;- solve(A) round(AinvI - Ainv, 4) ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 ## [4,] 0 0 0 0 Exercise 2 I renamed T into TM, as T is a logical TRUE in R. # square matrix A &lt;- matrix(rnorm(5^2), nrow=5, ncol=5) Ai &lt;- solve(A) Api &lt;- pracma::pinv(A) print(round(Ai - Api)) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## [3,] 0 0 0 0 0 ## [4,] 0 0 0 0 0 ## [5,] 0 0 0 0 0 # tall matrix TM &lt;- matrix(rnorm(5*3), nrow=5, ncol=3) TMl &lt;- solve(t(TM) %*% TM) %*% t(TM) TMpi &lt;- pracma::pinv(TM) print(round(TMl - TMpi)) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## [3,] 0 0 0 0 0 Chapter 13 Exercise 2 m &lt;- 4 n &lt;- 4 A &lt;- matrix(rnorm(n=m*n), nrow=m, ncol=n) Q &lt;- matrix(0, nrow=m, ncol=n) for(i in 1:n){ Q[, i] &lt;- A[, i] # orthogonalize a &lt;- A[, i] # convenience if (i &gt; 1){ for(j in 1:(i-1)){ q &lt;- Q[, j] # convenience Q[, i] &lt;- Q[, i] - pracma::dot(a, q) / pracma::dot(q, q) * q } } # normalize Q[, i] &lt;- Q[, i] / norm(matrix(Q[, i]), type=&quot;F&quot;) } QR &lt;- qr(A) Q2 &lt;- qr.Q(QR) Chapter 14 Exercise 3 # load the data into a table that we convert to a matrix df &lt;- read.csv(&quot;http://sincxpress.com/widget_data.txt&quot;, header=FALSE) data &lt;- as.matrix(df) # design matrix X &lt;- cbind(rep(1, nrow(data)), data[, 1:2]) colnames(X) &lt;- c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;) # outcome variable y &lt;- data[, 3] # beta coefficients[] beta &lt;- lsfit(X, y)$coefficients[1:3] ## Warning in lsfit(X, y): &#39;X&#39; matrix was collinear # scaled coefficients (intercept not scaled) betaScaled &lt;- beta / apply(X, MARGIN=2, FUN=sd) Exercise 4 library(dplyr) library(ggplot2) library(tidyr) df_long &lt;- df %&gt;% dplyr::rename(&quot;Time of day&quot; = 1, &quot;Age&quot; = 2, &quot;Widgets purchased&quot;=3) %&gt;% tidyr::pivot_longer(cols = c(&quot;Time of day&quot;, &quot;Age&quot;), names_to = &quot;Variable name&quot;, values_to = &quot;Variable&quot;) %&gt;% dplyr::mutate(`Variable name` = factor(`Variable name`, levels=c(&quot;Time of day&quot;, &quot;Age&quot;))) ggplot(df_long, aes(x = Variable, y=`Widgets purchased`)) + geom_point() + facet_grid(.~`Variable name`, scales=&quot;free_x&quot;) Exercise 5 yHat &lt;- X %*% beta r2 &lt;- 1 - sum((yHat - y)^2) / sum((y - mean(y))^2) Chapter 15 Exercise 1 avediffs &lt;- rep(0, times=100) for(n in 1:100){ A &lt;- matrix(rnorm(n=n^2), nrow=n, ncol=n) B &lt;- matrix(rnorm(n=n^2), nrow=n, ncol=n) l1 &lt;- geigen::geigen(A, B, symmetric=FALSE, only.values=TRUE)$values l2 &lt;- eigen(solve(B) %*% A)$values # important to sort eigvals l1 &lt;- sort(l1) l2 &lt;- sort(l2) avediffs[n] &lt;- mean(abs(l1-l2)) } ggplot(data=NULL, aes(x=1:100, y=avediffs)) + geom_point() + xlab(&quot;Matrix size&quot;) + ylab(expression(paste(Delta, lambda))) Exercise 2 A &lt;- diag(1:6) eigenA &lt;- eigen(A) L &lt;- eigenA$values V &lt;- eigenA$vectors Exercise 3 library(dplyr) library(ggplot2) library(patchwork) library(reshape2) v &lt;- 1:50 lstrow &lt;- c(v[length(v)], v[-length(v)]) H &lt;- pracma::hankel(v, lstrow) eigH &lt;- eigen(H) V &lt;- eigH$vectors[, order(eigH$values, decreasing=TRUE)] # the matrix plotH &lt;- ggplot(data=reshape2::melt(H), aes(x=1-Var1, y=Var2)) + geom_raster(aes(fill=value), show.legend=FALSE) + labs(title=&quot;Hankel matrix&quot;) + coord_equal() + xlab(&quot;&quot;) + ylab(&quot;&quot;) # eigenvector matrix plotV &lt;- ggplot(data=reshape2::melt(V), aes(x=Var2, y=Var1)) + geom_raster(aes(fill=value), show.legend=FALSE) + labs(title=&quot;Eigenvector matrix&quot;) + coord_equal() + xlab(&quot;&quot;) + ylab(&quot;&quot;) # a few eigenvectors dfV &lt;- data.frame(t(V)) %&gt;% dplyr::slice_head(n=4) %&gt;% dplyr::mutate(VectorIndex = 1:n()) %&gt;% tidyr::pivot_longer(cols = c(X1:X50), names_to=&quot;Element&quot;, values_to=&quot;Value&quot;) %&gt;% dplyr::group_by(VectorIndex) %&gt;% dplyr::mutate(ElementIndex = 1:n()) %&gt;% dplyr::select(-Element) plot4 &lt;- ggplot(data=dfV, aes(x = ElementIndex, y=Value, color=as.factor(VectorIndex))) + geom_line(show.legend=FALSE) + geom_point(show.legend=FALSE) + xlab(&quot;Eigenvector element index&quot;) + ylab(&quot;Eigenvector element value&quot;) + labs(title = &quot;First four eigenvectors&quot;) (plotH | plotV) / plot4 Chapter 16 Exercise 1 In R svd() defaults to economy mode. If you want the full matrix, you must specify dimensions for U and V explicitly. m &lt;- 6 n &lt;- 3 A &lt;- matrix(rnorm(n=m*n), nrow=m, ncol=n) fullSVD &lt;- svd(A, nu=m, nv=n) economySVD &lt;- svd(A) cat(sprintf(&quot;Full SVD: (%d, %d), %d, (%d, %d)\\n&quot;, nrow(fullSVD$u), ncol(fullSVD$u), length(fullSVD$d), nrow(fullSVD$v), ncol(fullSVD$v))) ## Full SVD: (6, 6), 3, (3, 3) cat(sprintf(&quot;Economy : (%d, %d), %d, (%d, %d)\\n&quot;, nrow(economySVD$u), ncol(economySVD$u), length(economySVD$d), nrow(economySVD$v), ncol(economySVD$v))) ## Economy : (6, 3), 3, (3, 3) Exercise 2 Note that eigen() sorts eigenvalues and eigenvectors, so sorting is redundant and can be skipped (but I kept it to match the original code). A &lt;- matrix(rnorm(n=4*5), nrow=4, ncol=5) # matrix A &lt;- matrix(a, nrow=4, ncol=5, byrow=TRUE) eigAV &lt;- eigen(t(A) %*% A) V &lt;- eigAV$vectors[, order(eigAV$values, decreasing=TRUE)] # sort descent V eigAU &lt;- eigen(A %*% t(A)) U &lt;- eigAU$vectors[, order(eigAU$values, decreasing=TRUE)] # sort descent U # create Sigma sorted_values &lt;- sort(eigAU$values, decreasing=TRUE) S &lt;- matrix(0, nrow=nrow(A), ncol=ncol(A)) for(i in 1:length(sorted_values)){ S[i, i] &lt;- sqrt(sorted_values[i]) } svdA &lt;- svd(A) # svd Exercise 3 library(ggplot2) library(patchwork) library(RColorBrewer) library(reshape2) A &lt;- matrix(rnorm(n=5*3), nrow=5, ncol=3) svdA &lt;- svd(A) S &lt;- diag(svdA$d) # need Sigma matrix fill_palette &lt;- colorRampPalette(rev(brewer.pal(11, &quot;Spectral&quot;))) sc &lt;- scale_colour_gradientn(colours = fill_palette(100), limits=c(min(A), max(A))) one_layer_plots &lt;- list() lowrank_plots &lt;- list() for(i in 1:3) { onelayer &lt;- outer(svdA$u[, i], svdA$v[i, ]) * svdA$d[i] one_layer_plots[[i]] &lt;- ggplot(data=reshape2::melt(t(onelayer)), aes(x=Var1, y=Var2, fill=value)) + geom_tile(show.legend=FALSE) + theme_void() + labs(title=sprintf(&quot;Layer %d&quot;, i)) + coord_equal() + sc lowrank &lt;- matrix(svdA$u[, 1:i], ncol=i) %*% S[1:i,1:i] %*% t(svdA$v)[1:i,] lowrank_plots[[i]] &lt;- ggplot(data=reshape2::melt(t(lowrank)), aes(x=Var1, y=Var2, fill=value)) + geom_tile(show.legend=FALSE) + theme_void() + labs(title=sprintf(&quot;Layers 1:%d&quot;, i)) + coord_equal() + sc } plotA &lt;- ggplot(data=reshape2::melt(t(A)), aes(x=Var1, y=Var2, fill=value)) + geom_tile(show.legend=FALSE) + theme_void() + labs(title=&quot;Orig. A&quot;) + coord_equal() + sc layout &lt;- &quot; ABC# DEFG &quot; one_layer_plots[[1]] + one_layer_plots[[2]] + one_layer_plots[[3]] + lowrank_plots[[1]] + lowrank_plots[[2]] + lowrank_plots[[3]] + plotA + plot_layout(design = layout) Exercise 4 m &lt;- 6 n &lt;- 16 condnum &lt;- 42 # create U and V from random numbers U &lt;- qr(matrix(rnorm(m*m), nrow=m, ncol=m)) V &lt;- qr(matrix(rnorm(n*n), nrow=n, ncol=n)) # create singular values vector s &lt;- seq(condnum, 1, length.out = min(c(m,n))) S &lt;- diag(s, nrow=m, ncol=n) #  original code  # S &lt;- matrix(0, nrow=m, ncol=n) # for(i in 1:min(c(m, n))){ # S[i, i] &lt;- s[i] # } A &lt;- qr.Q(U) %*% S %*% t(qr.Q(V)) # construct matrix pracma::cond(A) ## [1] 42 Exercise 5 library(imager) rankN &lt;- 20 picture &lt;- imager::load.image(&#39;https://upload.wikimedia.org/wikipedia/en/8/86/Einstein_tongue.jpg&#39;) pic &lt;- as.matrix(picture) picSVD &lt;- svd(pic, nu=nrow(pic), nv=ncol(pic)) S &lt;- diag(picSVD$d, nrow=nrow(pic), ncol=ncol(pic)) lowrank &lt;- picSVD$u[, 1:rankN] %*% S[1:rankN, 1:rankN] %*% t(picSVD$v)[1:rankN,] plot(imager::as.cimg(lowrank), axes=FALSE) Exercise 6 library(imager) # convert to percent explained s &lt;- 100 * picSVD$d / sum(picSVD$d) ggplot(data=NULL, aes(x=1:100, y=s[1:100])) + geom_line() + geom_point() + xlab(&quot;Component number&quot;) + ylab(&quot;Pct variance explains&quot;) thresh &lt;- 4 # threshold in percent comps &lt;- s &gt; thresh # comps greater than X% lowrank &lt;- picSVD$u[, comps] %*% S[comps, comps] %*% t(picSVD$v)[comps,] layout(t(c(1,2))) plot(picture, axes=FALSE, main=&quot;Original&quot;) plot(as.cimg(lowrank), axes=FALSE, main=sprintf(&quot;%s comps with &gt; %g%%&quot;, sum(comps), thresh)) Exercise 7 Note matrix(picSVD$u[, 1:si], ncol=si). Without matrix(, ncol=si), picSVD$u[, 1:si] becomes an atomic vector and matrix multiplication breaks down. library(ggplot2) RMS &lt;- rep(0, length(s)) for(si in 1:length(s)){ lowrank &lt;- matrix(picSVD$u[, 1:si], ncol=si) %*% S[1:si, 1:si] %*% t(picSVD$v)[1:si,] diffimg &lt;- lowrank - pic RMS[si] &lt;- sqrt(mean(diffimg^2)) } ggplot(data=NULL, aes(x=1:length(RMS), y=RMS)) + geom_line() + xlab(&quot;Rank approximation&quot;) + ylab(&quot;Error (a.u.)&quot;) Exercise 8 Reminder, you need to specify nu and nv to ensure full matrices U and V. library(matrixcalc) X &lt;- matrix(sample(1:6, size = 4*2, replace = TRUE), nrow=4, ncol=2) svdX &lt;- svd(X, nu=nrow(X), nv=ncol(X)) # eq. 29 U &lt;- svdX$u S &lt;- diag(svdX$d, nrow=nrow(X), ncol=ncol(X)) V &lt;- svdX$v longV1 &lt;- solve(t(U%*%S%*%t(V))%*%U%*%S%*%t(V)) %*% t(U%*%S%*%t(V)) # eq. 30 longV2 &lt;- solve(V%*%t(S)%*%t(U)%*%U%*%S%*%t(V)) %*% t(U%*%S%*%t(V)) # eq. 31 longV3 &lt;- solve(V%*%t(S)%*%S%*%t(V)) %*% t(U%*%S%*%t(V)) # eq. 32 longV4 &lt;- V %*% matrixcalc::matrix.power(t(S) %*% S, -1) %*% t(V)%*%V%*%t(S)%*%t(U) # eq. 33 MPpinv &lt;- pracma::pinv(X) # eq. 34 Exercise 9 k &lt;- 5 n &lt;- 13 a &lt;- pracma::pinv(matrix(1, nrow=n, ncol=1) * k) a - 1 / (k * n) # check for zeros ## [,1] [,2] [,3] [,4] [,5] ## [1,] 8.673617e-18 6.938894e-18 6.938894e-18 6.938894e-18 6.938894e-18 ## [,6] [,7] [,8] [,9] [,10] ## [1,] 6.938894e-18 6.938894e-18 6.938894e-18 6.938894e-18 6.938894e-18 ## [,11] [,12] [,13] ## [1,] 6.938894e-18 6.938894e-18 6.938894e-18 Exercise 10 M &lt;- 10 cns &lt;- seq(10, 1e10, length.out=30) avediffs &lt;- rep(0, length(cns)) # loop over condition numbers for(condi in 1:length(cns)){ # create A U &lt;- qr.Q(qr(matrix(rnorm(M^2), nrow=M, ncol=M))) V &lt;- qr.Q(qr(matrix(rnorm(M^2), nrow=M, ncol=M))) S &lt;- diag(cns[condi], nrow=M, ncol=M) A &lt;- U %*% S %*% t(V) # construct matrix # create B U &lt;- qr.Q(qr(matrix(rnorm(M^2), nrow=M, ncol=M))) V &lt;- qr.Q(qr(matrix(rnorm(M^2), nrow=M, ncol=M))) S &lt;- diag(cns[condi], nrow=M, ncol=M) B &lt;- U %*% S %*% t(V) # construct matrix # GEDs and sort l1 &lt;- sort(eigen(A)$values) l2 &lt;- sort(eigen(B)$values) avediffs[condi] &lt;- mean(abs(l1-l2)) } ggplot(data=NULL, aes(x=cns, y=avediffs)) + geom_line() + xlab(&quot;Cond. number&quot;) + ylab(expression(paste(Delta, lamda))) ## Chapter 17 ### Exercise 1 {-} library(plotly) A &lt;- matrix(c(-2, 3, 2, 8), nrow=2, ncol=2, byrow=TRUE) vi &lt;- seq(-2, 2, step=0.1) quadform &lt;- matrix(0, nrow=length(vi), ncol=length(vi)) for(i in 1:length(vi)){ for(j in 1:length(vi)){ v &lt;- matrix(c(vi[i], vi[j]), ncol=1) quadform[i, j] &lt;- t(v) %*% A %*% v / (t(v) %*% v) } } plot_ly(z = quadform, type = &quot;surface&quot;) Exercise 2 n &lt;- 4 nIterations &lt;- 500 defcat &lt;- rep(0, nIterations) for(iteri in 1:nIterations){ # create matrix A &lt;- matrix(sample(-10:10, size=n^2, replace=TRUE), nrow=n, ncol=n) e &lt;- eigen(A)$values while (is.complex(e)){ A &lt;- matrix(sample(-10:10, size=n^2, replace=TRUE), nrow=n, ncol=n) e &lt;- eigen(A)$values } # &quot;zero&quot; threshold (from rank) t &lt;- n * pracma::eps(max(svd(A)$d)) # test definiteness if (all(sign(e) == 1)) { defcat[iteri] &lt;- 1 # pos. def } else if (all(sign(e)&gt;-1 &amp; (sum(abs(e)&lt;t)&gt;0))){ defcat[iteri] &lt;- 2 # pos. semidef } else if (all(sign(e)&lt;1 &amp; (sum(abs(e)&lt;t)&gt;0))){ defcat[iteri] &lt;- 4 # neg. semidef } else if (all(sign(e) == -1)) { defcat[iteri] &lt;- 5 # neg. def } else { defcat[iteri] &lt;- 3 # indefinite } } # print out summary for(i in 1:5) { print(sprintf(&quot;cat %d: %d&quot;, i, sum(defcat == i))) } ## [1] &quot;cat 1: 1&quot; ## [1] &quot;cat 2: 0&quot; ## [1] &quot;cat 3: 498&quot; ## [1] &quot;cat 4: 0&quot; ## [1] &quot;cat 5: 1&quot; Chapter 18 Exercise 1 n &lt;- 200 X &lt;- matrix(rnorm(n*4), nrow=n, ncol=4) # data X &lt;- apply(X, MARGIN=2, FUN=scale, scale=FALSE) # mean-center covM &lt;- t(X) %*% X / (n-1) # covariance stdM &lt;- solve(diag(apply(X, MARGIN=2, FUN=sd))) # stdevs corM &lt;- stdM %*% t(X) %*% X %*% stdM / (n - 1) # R # compare ours against R&#39;s print(round(covM - cov(X), 3)) ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 ## [4,] 0 0 0 0 print(round(corM - cor(X), 3)) ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 ## [4,] 0 0 0 0 Chapter 19 Exercise 1 library(ggplot2) # create data N &lt;- 1000 h &lt;- rnorm(n=N, mean = seq(150, 190, length.out = N), sd=5) w &lt;- h * .7 - 50 + rnorm(N, mean=0, sd=10) # covariance X &lt;- cbind(h, w) X &lt;- apply(X, MARGIN=2, scale, scale=FALSE) C &lt;- t(X) %*% X / (length(h) - 1) # PCA eigC &lt;- eigen(C) # sorting below is redundant in R, as values and vectors are presorted i &lt;- order(eigC$values, decreasing=TRUE) V &lt;- eigC$vectors[, i] eigvals &lt;- eigC$values[i] eigvals &lt;- 100 * eigvals / sum(eigvals) scores &lt;- X %*% V # not used, but useful code # plot data with PCs ggplot(data=NULL, aes(x = X[, 1], y = X[, 2])) + geom_point() + geom_segment(aes(x=0, y=0, xend=V[1, 1] * 45, yend=V[2, 1] * 45), color=&quot;red&quot;, size=2) + geom_segment(aes(x=0, y=0, xend=V[1, 2] * 25, yend=V[2, 2] * 25), color=&quot;red&quot;, size=2) + scale_x_continuous(name=&quot;Height&quot;, limits=c(-50, 50)) + scale_y_continuous(name=&quot;Weight&quot;, limits=c(-50, 50)) + coord_equal() Exercise 2 X &lt;- apply(X, MARGIN=2, scale, scale=FALSE) svdX &lt;- svd(X, nu=nrow(X), nv=ncol(X)) scores &lt;- X %*% svdX$v s &lt;- diag(svdX$d)^2 / (nrow(X) - 1) s &lt;- 100 * s / sum(s) # s == eigvals Exercise 3 library(ggplot2) # create data N &lt;- 1000 h &lt;- rnorm(n=N, mean = seq(150, 190, length.out = N), sd=5) w &lt;- h * .7 - 50 + rnorm(N, mean=0, sd=10) # covariance X &lt;- cbind(h, w) C &lt;- t(X) %*% X / (length(h) - 1) # PCA eigC &lt;- eigen(C) # sorting below is redundant in R, as values and vectors are presorted i &lt;- order(eigC$values, decreasing=TRUE) V &lt;- eigC$vectors[, i] eigvals &lt;- eigC$values[i] eigvals &lt;- 100 * eigvals / sum(eigvals) scores &lt;- X %*% V # not used, but useful code # now we center the data X &lt;- apply(X, MARGIN=2, scale, scale=FALSE) # plot data with PCs ggplot(data=NULL, aes(x = X[, 1], y = X[, 2])) + geom_point() + geom_segment(aes(x=0, y=0, xend=V[1, 1] * 45, yend=V[2, 1] * 45), color=&quot;red&quot;, size=2) + geom_segment(aes(x=0, y=0, xend=V[1, 2] * 25, yend=V[2, 2] * 25), color=&quot;red&quot;, size=2) + scale_x_continuous(name=&quot;Height&quot;, limits=c(-50, 50)) + scale_y_continuous(name=&quot;Weight&quot;, limits=c(-50, 50)) + coord_equal() "],["function-references.html", "Function references C D E G H I L M N O P Q R S T U V", " Function references C Complex numbers in R: complex() Complex conjugate: Conj() Concatenating matrices by columns cbind() or rows rbind() Condition of matrix: pracma::cond() Cross product: crossprod() D Determinant: det() Diagonal: diag() Dot product: pracma::dot() E Eigenvalues and eigenvectors: eigen() G Generalized Eigenvalues: giegen::geigen() H Hankel matrix: pracma::hankel() I Inverse of a matrix: solve() L Least-squares solution to a linear matrix equation: lsfit() Lower triangular part of a matrix: pracma::tril() and lower.tri() for logical indexes (excluding diagonal by default). LU decomposition: pracma::lu() M Matrix, concatenating by columns cbind() or rows rbind() Matrix condition: pracma::cond() Matrix, creating: matrix() Matrix, determinant: det() Matrix diagonal: diag() Matrix dimensions: dim() Matrix eigenvalues and eigenvectors: eigen Matrix inverse: solve() Matrix is symmetric (real valued) or Hermitian (complex values): isSymmetric() Matrix multiplication: %*% Matrix norm: norm() Matrix to the power: matrixcalc::matrix.power() Matrix pseudoinverse: pracma::pinv() Matrix rank: pracma::Rank() Matrix trace: pracma::Trace() Matrix, triangular parts. Lower pracma::tril() and upper pracma::triu(). Logical indexes (excluding diagonal by default): lower.tri() and upper.tri(). N Norm of matrix: norm() Null space: pracma::nullspace() O Outer product: outer() P Power function for matrix: matrixcalc::matrix.power() Pseudoinverse: pracma::pinv() Q QR decomposition: qr(). To reconstruct Q, R, or X matrices see qr auxiliaries. R Random numbers from a normal distribution: rnorm() Random numbers from a uniform distribution: runif() Rank: pracma::Rank() Reduced Row Echelon Form: pracma::rref() S Sampling from list of numbers (used in the code to sample integers from a range): sample() Singular value decomposition: svd() T Toeplitz matrix: toeplitz() Trace: pracma::Trace() Transpose: t() Triangular parts of matrix. Lower pracma::tril() and upper pracma::triu(). Logical indexes (excluding diagonal by default): lower.tri() and upper.tri(). U Upper triangular part of a matrix: pracma::triu() and upper.tri() for logical indexes (excluding diagonal by default). V Vector, creating or converting to an atomic vector: c() Vector, converting to an atomic vector: as.vector() "]]
